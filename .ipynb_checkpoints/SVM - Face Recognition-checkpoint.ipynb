{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
      "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
      "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot some faces\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use a principal component analysis \n",
    "#to extract 150 fundamental components to feed into our support vector machine classifier.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search crossvalidation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "yfit = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at a few of the test images along with their predicted values:\n",
    "fig, ax = plt.subplots(4, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a better sense of our estimator's performance using the classification report, \n",
    "#which lists recovery statistics label by label:\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, yfit,\n",
    "                            target_names=faces.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the confusion matrix between these classes\n",
    "#This helps us get a sense of which labels are likely to be confused by the estimator.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
